{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Advanced Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from functools import reduce\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, GlobalAveragePooling1D, Flatten, Conv1D, GlobalMaxPooling1D, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import csr_matrix\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_cleaned = pd.read_csv('cleaned_dataset.csv') \n",
    "#Omitting 'unknown', 'unreliable' and 'rumor' types and dropping nan values\n",
    "df_big_cleaned = df_big_cleaned.dropna(subset=['type'])\n",
    "df_big_cleaned = df_big_cleaned[df_big_cleaned['type'] != 'unknown']\n",
    "df_big_cleaned = df_big_cleaned[df_big_cleaned['type'] != 'unreliable']\n",
    "df_big_cleaned = df_big_cleaned[df_big_cleaned['type'] != 'rumor']\n",
    "\n",
    "#Grouping the types 'bias','clickbait','conspiracy','fake','hate','junksci','unreliable' into 'fake'\n",
    "df_big_cleaned['type'] = df_big_cleaned['type'].replace(['bias','conspiracy','fake','hate','junksci','satire'],'fake')\n",
    "df_big_cleaned['type'] = df_big_cleaned['type'].replace(['political','reliable','clickbait'],'reliable')\n",
    "df_big_cleaned = df_big_cleaned[['content','type']]\n",
    "\n",
    "#Splitting data into training, validation and test data\n",
    "reliable = pd.read_csv('reliable_scraped_data.csv') #reading the csv file as a pandas dataframe#\n",
    "reliable['type'] = 'reliable'\n",
    "reliable = reliable[['content','type']]\n",
    "\n",
    "#Adding the reliable data to our dataset \n",
    "concatenated_data = pd.concat([df_big_cleaned,reliable],axis=0)\n",
    "concatenated_data.drop(concatenated_data[concatenated_data['type'] == '2018-02-10 13:43:39.521661'].index, inplace=True)\n",
    "label_mapping = {\"fake\": 0, \"reliable\": 1}\n",
    "concatenated_data['type'] = concatenated_data['type'].replace(label_mapping)\n",
    "concatenated_data = concatenated_data.iloc[:, 0:2]\n",
    "concatenated_data = concatenated_data.dropna().reset_index(drop=True)\n",
    "print(concatenated_data)\n",
    "\n",
    "#Defining our x to be our input data from the content column and y to be the type column\n",
    "x=concatenated_data['content']\n",
    "print(x.shape)\n",
    "y=concatenated_data['type']\n",
    "\n",
    "#Splitting the data into training, validation and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_test, y_test, test_size=0.5,random_state=42)\n",
    "y_train = y_train.astype(int)\n",
    "y_validation = y_validation.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "print(y.isna().sum())\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for cleaning, stemming and removing stopwords\n",
    "def remove_stopwords(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = str(data).split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def stem_input(data):\n",
    "    ps = PorterStemmer()\n",
    "    words = str(data).split()\n",
    "    return reduce(lambda x, y: x + ' ' + ps.stem(y), words, '')\n",
    "\n",
    "def cleantext_clean(data):\n",
    "    #As clean did not have arguments for date we wrote our own using regular expressions\n",
    "    date_formats = [\n",
    "        r'\\d{2,4}/\\d{1,2}/\\d{2,4}(.*)',   # e.g 12/31/2021 or 12/31/21\n",
    "        r'\\d{2,4}-\\d{1,2}-\\d{2,4}(.*)',   # e.g 12-31-2021 or 12-31-21\n",
    "        ]\n",
    "\n",
    "    for date_format in date_formats:\n",
    "        data = re.sub(date_format, '<DATE>', str(data))\n",
    "\n",
    "    data = clean(data, lower=True, normalize_whitespace=True, no_urls=True, no_emails = True, no_numbers= True,\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_number=\"<NUM>\",)\n",
    "    return data\n",
    "\n",
    "#Cleaning the LIAR-dataset for testing\n",
    "liar_dataset = pd.read_csv('test.tsv',sep='\\t', header=None)\n",
    "liar_dataset[1].unique()\n",
    "liar_dataset = liar_dataset[liar_dataset[1] != 'half-true']\n",
    "liar_dataset[1] = liar_dataset[1].replace(['false','barely-true','pants-fire'],0)\n",
    "liar_dataset[1] = liar_dataset[1].replace(['true','mostly-true'],1)\n",
    "x_liar=liar_dataset[2]\n",
    "y_liar=liar_dataset[1]\n",
    "x_liar = x_liar.apply(cleantext_clean)\n",
    "x_liar = x_liar.apply(remove_stopwords)\n",
    "x_liar = x_liar.apply(stem_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the simple model on the LIAR-dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#Loading the CountVectorizer used for training\n",
    "with open('vectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "#Transforming validation data using the same CountVectorizer\n",
    "x_liar_vec = vectorizer.transform(x_liar)\n",
    "\n",
    "#Loading the trained model\n",
    "with open('trained_model_content.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "#Making predictions on validation data\n",
    "y_pred = model.predict(x_liar_vec)\n",
    "\n",
    "y_pred = pd.DataFrame({'type': y_pred})\n",
    "y_pred = y_pred.replace(label_mapping)\n",
    "#Calculating accuracy\n",
    "acc = accuracy_score(y_liar, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the advanced model on the LIAR-dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "#Tokenizing the data\n",
    "tokenizer = Tokenizer(num_words=40000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "#Converting the text to sequences\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_validation = tokenizer.texts_to_sequences(x_validation)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_liar = tokenizer.texts_to_sequences(x_liar)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "#Padding the sequences\n",
    "max_sequence_length = 100\n",
    "x_train = pad_sequences(x_train, maxlen=max_sequence_length,padding='post')\n",
    "x_validation = pad_sequences(x_validation, maxlen=max_sequence_length,padding='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_sequence_length,padding='post')\n",
    "x_liar = pad_sequences(x_liar, maxlen=max_sequence_length,padding='post')\n",
    "\n",
    "#Converting the sequences back to text\n",
    "sentences = tokenizer.sequences_to_texts(x_train)\n",
    "sentences = [article.split() for article in sentences]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "#Creating a weight matrix for the embedding layer\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matrix[i] = word2vec_model.wv[word]\n",
    "        \n",
    "#Setting up early stopping callback \n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3,restore_best_weights=True)\n",
    "\n",
    "#Building the model \n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100,embeddings_initializer=Constant(embedding_matrix), trainable=False))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(x_train, y_train, epochs=30, batch_size=256, validation_data=(x_validation, y_validation),callbacks=[callback])\n",
    "\n",
    "#Evaluating the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('Test Accuracy: ', accuracy)\n",
    "loss_liar, accuracy_liar = model.evaluate(x_liar, y_liar)\n",
    "print('Liar Accuracy: ', accuracy_liar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to make a confusion matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def make_confusion_matrix(cf, group_names=None, categories='auto', count=True, percent=True, cbar=True, xyticks=True,\n",
    "                          xyplotlabels=True, sum_stats=True, figsize=None, cmap='Blues', title=None):\n",
    "\n",
    "    # Function to generate text inside each square\n",
    "    def generate_labels(cf, count, percent):\n",
    "        blanks = ['' for _ in range(cf.size)]\n",
    "        if group_names and len(group_names) == cf.size:\n",
    "            group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "        else:\n",
    "            group_labels = blanks\n",
    "\n",
    "        if count:\n",
    "            group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "        else:\n",
    "            group_counts = blanks\n",
    "\n",
    "        if percent:\n",
    "            group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten() / np.sum(cf)]\n",
    "        else:\n",
    "            group_percentages = blanks\n",
    "\n",
    "        box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in\n",
    "                      zip(group_labels, group_counts, group_percentages)]\n",
    "        return np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n",
    "\n",
    "    box_labels = generate_labels(cf, count, percent)\n",
    "\n",
    "    #Setting figure parameters according to other arguments\n",
    "    if figsize is None:\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if not xyticks:\n",
    "        categories = False\n",
    "\n",
    "    colors = ['Reds', 'Greens']\n",
    "\n",
    "    # Makeing the heatmap visualization\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf, annot=box_labels, fmt=\"\", cmap=cmap, cbar=cbar, xticklabels=categories, yticklabels=categories, \n",
    "                mask=cf == 0)  # Mask zeros to avoid displaying empty cells\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.show() \n",
    "    \n",
    "\n",
    " #Generating confusion matrix and f1-score for the the advanced model    \n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "#Calculating F1-score\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "#Generating confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix) \n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['Fake', 'Real']\n",
    "\n",
    "make_confusion_matrix(conf_matrix, group_names=labels, categories=categories, cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
